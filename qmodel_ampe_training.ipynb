{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e2d47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "from pennylane import numpy as np\n",
    "import pennylane as qml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Parse the script arguments.\"\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--dataset-path\",\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help=\"Path to the dataset.\"\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--output-dir\",\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help=\"Path to the output directory.\"\n",
    "    )\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "def ingest_dataset(path, n_pkts=10, n_features=4):\n",
    "    with open(path, \"rb\") as f:\n",
    "        biflows = pickle.load(f)\n",
    "        labels = pickle.load(f)\n",
    "    biflows = np.array(biflows)[:,:n_pkts,:n_features]\n",
    "    return biflows, labels\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Parsing degli argomenti\n",
    "    args = get_args()\n",
    "    dataset_path = args.dataset_path\n",
    "    output_dir = args.output_dir\n",
    "\n",
    "    n_pkts = 10\n",
    "    n_features = 4\n",
    "    seed = 2025\n",
    "    \n",
    "    n_qubits = 5\n",
    "    n_layers = 3\n",
    "\n",
    "    # Riproducibilità\n",
    "    np.random.seed(seed)                    # NumPy\n",
    "    tf.random.set_seed(seed)                # TensorFlow\n",
    "    tf.keras.utils.set_random_seed(seed)    # Keras\n",
    "\n",
    "    # Caricamento del dataset\n",
    "    X, y = ingest_dataset(dataset_path, n_pkts=n_pkts, n_features=n_features)\n",
    "    num_classes = len(np.unique(y))\n",
    "\n",
    "    # Codifica delle label\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "\n",
    "    # Partizionamento in train, validation e test set (proporzioni 80/20, 80/20)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y,\n",
    "    )\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler.fit(np.reshape(X_train, [-1, n_features]))\n",
    "    res_samples_train = scaler.transform(np.reshape(X_train, [-1, n_features]))\n",
    "    res_samples_test = scaler.transform(np.reshape(X_test, [-1, n_features]))\n",
    "    X_train = np.reshape(res_samples_train, [-1, n_pkts, n_features])\n",
    "    X_test = np.reshape(res_samples_test, [-1, n_pkts, n_features])\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=seed, stratify=y_train,\n",
    "    )\n",
    "\n",
    "    ohe_y_train = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
    "    ohe_y_valid = tf.keras.utils.to_categorical(y_valid, num_classes=num_classes)\n",
    "\n",
    "    # Definizione del circuito quantistico\n",
    "    dev = qml.device(\"default.qubit\", seed=seed, wires=n_qubits)\n",
    "    @qml.qnode(dev , interface=\"tf\")\n",
    "    def qnode(inputs, weights):\n",
    "        \n",
    "        # Feature map\n",
    "        qml.AmplitudeEmbedding(inputs, wires=range(n_qubits), normalize=True, pad_with=0.0)\n",
    "\n",
    "        # Ansatz\n",
    "        qml.StronglyEntanglingLayers(weights, wires=range(n_qubits))\n",
    "\n",
    "        # Processo di misurazione\n",
    "        return qml.probs(wires=range(n_qubits))\n",
    "\n",
    "    # Pesi dell'ansatz\n",
    "    weights = np.random.rand(n_layers*n_qubits*3).reshape(n_layers,n_qubits,3)\n",
    "    weights = tf.Variable(weights, dtype=tf.float64, trainable=True)\n",
    "    weight_shapes = {\"weights\": (n_layers,n_qubits,3)}\n",
    "\n",
    "    #Definizione del modello\n",
    "    model = Sequential(name='ampe_fixed_probs')\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(2**n_qubits,activation='sigmoid', input_dim=n_pkts*n_features))\n",
    "    model.add(qml.qnn.KerasLayer(qnode, weight_shapes, output_dim=2**n_qubits)) # <-- qui c'è la parte quantum\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.build(np.shape(X_train))\n",
    "\n",
    "    tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    earlystop = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "    callbacks = [earlystop]\n",
    "\n",
    "    os.makedirs(f\"{output_dir}\", exist_ok=True)\n",
    "\n",
    "    with open(f\"{output_dir}/model_summary.txt\", \"w\") as f:\n",
    "        model.summary(print_fn=lambda x: f.write(x + \"\\n\"))\n",
    "\n",
    "    history = model.fit(X_train, ohe_y_train, validation_data=(X_valid,ohe_y_valid),\n",
    "                    epochs=1, batch_size=50,\n",
    "                    callbacks=callbacks, verbose=2)\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    df_history = pd.DataFrame(history.history)\n",
    "    df_history.to_csv(f\"{output_dir}/training_history.csv\", index=False)\n",
    "\n",
    "    y_pred_probs = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "    # Salvataggio dei risultati\n",
    "    soft_values = [\",\".join(map(str, probs)) for probs in y_pred_probs]\n",
    "    df_soft = pd.DataFrame({\n",
    "        \"Actual\": y_test,\n",
    "        \"soft_values\": soft_values\n",
    "    })\n",
    "    df_pred = pd.DataFrame({\n",
    "        \"Actual\": y_test,\n",
    "        \"Predicted\": y_pred\n",
    "    })\n",
    "\n",
    "    df_soft.to_csv(f\"{output_dir}/soft_values.dat\", sep=\"\\t\", index=False)\n",
    "    df_pred.to_csv(f\"{output_dir}/predictions.dat\", sep=\"\\t\", index=False)\n",
    "    labels_map = {}\n",
    "    for c, enc_c in zip(le.classes_, le.transform(le.classes_)):\n",
    "        labels_map[str(enc_c)] = c\n",
    "    with open(f\"{output_dir}/labels_map.json\", 'w') as f:\n",
    "        json.dump(labels_map, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
